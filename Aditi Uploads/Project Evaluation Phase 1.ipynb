{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Module 1: Input\n",
    "\n",
    "## Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk \n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model for English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input from user of words whos sentence has to be made\n",
    "\n",
    "As of now, the input being taken is a sequence  of words. But the input can also be taken in as a list or a tuple as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i stay pune\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(input(\"> \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Module 2: Preprocessing\n",
    "\n",
    "## Perform Tagging of Part Of Speech with depth of the word used. \n",
    "\n",
    "With the help of spacy library, we are implementing a for loop, in which every word in the sequence can get its POS tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ->Token i \n",
      "POS: PRP, \n",
      "dep: nsubj\n",
      " ->Token stay \n",
      "POS: VBP, \n",
      "dep: ROOT\n",
      " ->Token pune \n",
      "POS: NN, \n",
      "dep: attr\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "   print(\" ->Token {} \\nPOS: {}, \\ndep: {}\".format(token.text, token.tag_, token.dep_))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['stay']\n"
     ]
    }
   ],
   "source": [
    "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Subject -Verb Object Extraction\n",
    "\n",
    "## Determine Subject,Wh- words and Object Constants\n",
    "\n",
    "The way a word in the sequence can appear by determining the constants which will help in identifying Synatctic Dependency relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECT_DEPS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}\n",
    "SUBJECT_DEPS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"agent\", \"expl\"}\n",
    "WH_WORDS = {\"WP\", \"WP$\", \"WRB\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Subject, Verb and Object in the existing words\n",
    "\n",
    "Subject, Verb and Object are extracted from the token.dep_ feature of words whose POS is identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_svo(doc):\n",
    "    sub = []\n",
    "    at = []\n",
    "    print(type(at))\n",
    "    ve = []\n",
    "    for token in doc:\n",
    "        # is this a verb?\n",
    "        if token.pos_ == \"VERB\":\n",
    "            ve.append(token.text)\n",
    "        # is this the object?\n",
    "        if token.dep_ in OBJECT_DEPS or token.head.dep_ in OBJECT_DEPS:\n",
    "            at.append(token.text)\n",
    "        # is this the subject?\n",
    "        if token.dep_ in SUBJECT_DEPS or token.head.dep_ in SUBJECT_DEPS:\n",
    "            sub.append(token.text)\n",
    "    return \" \".join(sub).strip().lower(), \" \".join(ve).strip().lower(), \" \".join(at).strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if a question exists\n",
    "\n",
    "The Tag of a question helps to recognize a WH- word in the sequence of words, and accordingly to find if a question is stated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(doc):\n",
    "    # is the first token a verb?\n",
    "    if len(doc) > 0 and doc[0].pos_ == \"VERB\":\n",
    "        return True, \"\"\n",
    "    # go over all words\n",
    "    for token in doc:\n",
    "        # is it a wh- word?\n",
    "        if token.tag_ in WH_WORDS:\n",
    "            return True, token.text.lower()\n",
    "    return False, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "svo:, \n",
      "subject: i, \n",
      "verb: stay, \n",
      "attribute: pune, \n",
      "question: False, wh_word: \n"
     ]
    }
   ],
   "source": [
    "subject, verb, attribute = extract_svo(doc)\n",
    "question, wh_word = is_question(doc)\n",
    "print(\"svo:, \\nsubject: {}, \\nverb: {}, \\nattribute: {}, \\nquestion: {}, wh_word: {}\".format(subject, verb, attribute, question, wh_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "type(attribute)\n",
    "attribute_present = False\n",
    "if(not(attribute and attribute.strip())): \n",
    "    attribute_present = False  \n",
    "else : \n",
    "    attribute_present = True\n",
    "print(attribute_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Grammar Rules Designing \n",
    "\n",
    "## Create a complete sentence\n",
    "\n",
    "Demo of how Parsing functions can be done. This one is done on the basis of only one use case of the sequence, \n",
    "\n",
    "\"I stay Pune\"\n",
    "\n",
    "The accurate prediction of appropriate preposition and similarly prefix, suffix etc will be accordingly done.\n",
    "\n",
    "<img src= \"tree.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble(*args):\n",
    "    return \" \".join(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_preposition(attribute):\n",
    "    return assemble(\"in\", attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence(NP,VP):\n",
    "    return assemble(NP,VP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NP(T,N):\n",
    "    return assemble(T,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VP(Verb,N):\n",
    "    return assemble(Verb,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "stay\n"
     ]
    }
   ],
   "source": [
    "print(subject)\n",
    "print(verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Parsing Trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i stay in pune\n"
     ]
    }
   ],
   "source": [
    "VP1 = VP(verb,determine_preposition(attribute))\n",
    "output = sentence(subject,VP1) \n",
    "print(output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I stay in Pune\" is the output for this demo test case.\n",
    "\n",
    "Here we had only one preposition to be added. Many use cases cannot be satisfied by these functions.\n",
    "Tenses are also a major factor determining the sentence structure. At the moment, we are brainstorming on them\n",
    "\n",
    "Determining Appropriate stop words, prepositions, and tense of the sentences is the Objective which we will be working on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
