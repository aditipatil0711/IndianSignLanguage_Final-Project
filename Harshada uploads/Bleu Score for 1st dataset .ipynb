{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['I', 'want', 'food']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']], [['We', 'will', 'go', 'together', 'tomorrow']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']], [['We', 'will', 'go', 'together', 'tomorrow']], [['What', 'is', 'todays', 'date?']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']], [['We', 'will', 'go', 'together', 'tomorrow']], [['What', 'is', 'todays', 'date?']], [['I', 'like', 'pink', 'color']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']], [['We', 'will', 'go', 'together', 'tomorrow']], [['What', 'is', 'todays', 'date?']], [['I', 'like', 'pink', 'color']], [['a', 'child', 'eats', 'an', 'apple']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']], [['We', 'will', 'go', 'together', 'tomorrow']], [['What', 'is', 'todays', 'date?']], [['I', 'like', 'pink', 'color']], [['a', 'child', 'eats', 'an', 'apple']], [['this', 'is', 'a', 'flower']]]\n",
      "[[['I', 'want', 'food']], [['I', 'came']], [['I', 'stay', 'in', 'pune']], [['What', 'is', 'your', 'name?']], [['Where', 'is', 'the', 'bank?']], [['I', 'did', 'not', 'understand']], [['Father', 'is', 'a', 'clerk']], [['What', 'is', 'your', 'name?']], [['We', 'will', 'go', 'together', 'tomorrow']], [['What', 'is', 'todays', 'date?']], [['I', 'like', 'pink', 'color']], [['a', 'child', 'eats', 'an', 'apple']], [['this', 'is', 'a', 'flower']], [['it', 'is', '9', 'in', 'the', 'morning']]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e97b826427fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#print(stripped_line)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mline_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstripped_line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mline_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'<eos>'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mlayer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a_file = open(\"ref1.txt\", \"r\")\n",
    "def cloning(li):\n",
    "    new_li=[]\n",
    "    for item in li:\n",
    "        new_li.append(item)\n",
    "    return new_li    \n",
    "\n",
    "layer1 = []\n",
    "layer2 = []\n",
    "\n",
    "\n",
    "for line in a_file:\n",
    "    stripped_line = line.strip()\n",
    "    #print(stripped_line)\n",
    "    line_list = stripped_line.split()\n",
    "    if line_list[-1]!='<eos>':\n",
    "        layer2.append(line_list)\n",
    "    else:\n",
    "        layer2.append(line_list[:len(line_list)-1])\n",
    "        \n",
    "    #print(layer2)\n",
    "    if line_list[-1]=='<eos>':\n",
    "       \n",
    "        layer1.append(cloning(layer2))\n",
    "        print(layer1)\n",
    "        layer2.clear()\n",
    "        #print(layer1)\n",
    "        \n",
    "#print(layer1)       \n",
    "\n",
    "#layer1 ->[[['I', 'want', 'food'], ['I', 'want', 'the', 'food', '<eos>']]]\n",
    "#layer1 ->[[]] ->[layer2]\n",
    "#layer2 ->[['I', 'came', '<eos>']]\n",
    "#layer1 ->[[['I', 'came', '<eos>']]]\n",
    "#layer1 ->[[],[]]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_file = open(\"ref.txt\", \"r\")\n",
    "\n",
    "\n",
    "list_of_lists_ = []\n",
    "\n",
    "for line in b_file:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    list_of_lists_.append(line_list)\n",
    "\n",
    "\n",
    "b_file.close()\n",
    "\n",
    "\n",
    "print(list_of_lists_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def _get_ngrams(segment, max_order):\n",
    "  \"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n",
    "  Args:\n",
    "    segment: text segment from which n-grams will be extracted.\n",
    "    max_order: maximum length in tokens of the n-grams returned by this\n",
    "        methods.\n",
    "  Returns:\n",
    "    The Counter containing all n-grams upto max_order in segment\n",
    "    with a count of how many times each n-gram occurred.\n",
    "  \"\"\"\n",
    "  ngram_counts = collections.Counter()\n",
    "  for order in range(1, max_order + 1):\n",
    "    for i in range(0, len(segment) - order + 1):\n",
    "      ngram = tuple(segment[i:i+order])\n",
    "      ngram_counts[ngram] += 1\n",
    "  return ngram_counts\n",
    "\n",
    "\n",
    "def compute_bleu(reference_corpus, translation_corpus, max_order=4,\n",
    "                 smooth=False):\n",
    "  \"\"\"Computes BLEU score of translated segments against one or more references.\n",
    "  Args:\n",
    "    reference_corpus: list of lists of references for each translation. Each\n",
    "        reference should be tokenized into a list of tokens.\n",
    "    translation_corpus: list of translations to score. Each translation\n",
    "        should be tokenized into a list of tokens.\n",
    "    max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
    "  Returns:\n",
    "    3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n",
    "    precisions and brevity penalty.\n",
    "  \"\"\"\n",
    "  matches_by_order = [0] * max_order\n",
    "  possible_matches_by_order = [0] * max_order\n",
    "  reference_length = 0\n",
    "  translation_length = 0\n",
    "  for (references, translation) in zip(reference_corpus,\n",
    "                                       translation_corpus):\n",
    "    reference_length += min(len(r) for r in references)\n",
    "    translation_length += len(translation)\n",
    "\n",
    "    merged_ref_ngram_counts = collections.Counter()\n",
    "    for reference in references:\n",
    "      merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
    "    translation_ngram_counts = _get_ngrams(translation, max_order)\n",
    "    overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
    "    for ngram in overlap:\n",
    "      matches_by_order[len(ngram)-1] += overlap[ngram]\n",
    "    for order in range(1, max_order+1):\n",
    "      possible_matches = len(translation) - order + 1\n",
    "      if possible_matches > 0:\n",
    "        possible_matches_by_order[order-1] += possible_matches\n",
    "\n",
    "  precisions = [0] * max_order\n",
    "  for i in range(0, max_order):\n",
    "    if smooth:\n",
    "      precisions[i] = ((matches_by_order[i] + 1.) /\n",
    "                       (possible_matches_by_order[i] + 1.))\n",
    "    else:\n",
    "      if possible_matches_by_order[i] > 0:\n",
    "        precisions[i] = (float(matches_by_order[i]) /\n",
    "                         possible_matches_by_order[i])\n",
    "      else:\n",
    "        precisions[i] = 0.0\n",
    "\n",
    "  if min(precisions) > 0:\n",
    "    p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n",
    "    geo_mean = math.exp(p_log_sum)\n",
    "  else:\n",
    "    geo_mean = 0\n",
    "\n",
    "  ratio = float(translation_length) / reference_length\n",
    "\n",
    "  if ratio > 1.0:\n",
    "    bp = 1.\n",
    "  else:\n",
    "    bp = math.exp(1 - 1. / ratio)\n",
    "\n",
    "  bleu = geo_mean * bp\n",
    "  return (bleu, precisions, bp, ratio, translation_length, reference_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bleu(layer1,list_of_lists_,4,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
